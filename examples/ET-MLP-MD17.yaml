activation: silu
aggr: add
atom_filter: -1
attn_activation: silu
batch_size: 8
coord_files: null
cutoff_lower: 0.0
cutoff_upper: 5.0
dataset: MD17
dataset_arg:
  molecules: aspirin,benzene,malonaldehyde,naphtalene,toluene,salicylic_acid,uracil,paracetamol
dataset_root: ~/data
derivative: true # its for forces
distance_influence: both
early_stopping_patience: 300
ema_alpha_neg_dy: 1.0
ema_alpha_y: 0.05
embed_files: null
embedding_dimension: 128
energy_files: null
y_weight: 0.2 # opposite of the neg_dy_weight
force_files: null
neg_dy_weight: 0.8 # This affect the total loss and give the weigh to force loss for training
#inference_batch_size: 64
load_model: null
log_dir: logs/
lr: 0.001
lr_factor: 0.8
lr_min: 1.0e-07
lr_patience: 30
lr_warmup_steps: 1000
max_num_neighbors: 32
max_z: 100
model: equivariant-transformer-x
neighbor_embedding: true
ngpus: -1
num_epochs: 3000
num_heads: 8
num_layers: 6
num_nodes: 1
num_rbf: 32
num_workers: 6
output_model: Scalar
precision: 32
prior_model: null
rbf_type: expnorm
redirect: false
reduce_op: add
save_interval: 10
splits: null
standardize: true
test_interval: 10
test_size: 100
train_size: 1000
trainable_rbf: false
val_size: 100
weight_decay: 0.0
box_vecs: null
charge: false
spin: false
vector_cutoff: true
wandb_use: true
wandb_project: MLP-MD17-Ethanol
tensorboard_use: true
wandb_name: ET-Transformer-HardCoded_repr
